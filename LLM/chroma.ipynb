{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703165cc-3237-4afe-8977-6d9fd587f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f0f95e-a3e9-4575-ba91-938a3ceea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b183c452-46df-44d1-b108-6b50a86d8256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 23:26:43.001025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744126003.250145  275702 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744126003.320831  275702 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744126003.822303  275702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744126003.822375  275702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744126003.822382  275702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744126003.822387  275702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b59bf7-1b9d-496d-bc6f-1c05b45cda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Apple is a fruit\", \"Cars are vehicles\", \"I love mangoes\"]\n",
    "\n",
    "embeddings = embedder.encode(texts).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9028f35-2562-4731-a485-2d40d6a94f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./test-chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d342f2ee-cfaf-40a7-9c45-2ed38e65ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(\"test-data\")\n",
    "\n",
    "# Store data\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=texts,\n",
    "    metadatas=[{\"topic\": \"fruit\"}, {\"topic\": \"vehicle\"}, {\"topic\": \"fruit\"}],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18de035c-dc2c-492e-a53c-4178427dab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['doc1', 'doc3']], 'embeddings': None, 'documents': [['Apple is a fruit', 'I love mangoes']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[{'topic': 'fruit'}, {'topic': 'fruit'}]], 'distances': [[0.7356013059616089, 1.1305949687957764]]}\n"
     ]
    }
   ],
   "source": [
    "def query(text):\n",
    "    query_embedding = embedder.encode(text).tolist()\n",
    "    return collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=2 # how many results to return\n",
    "    )\n",
    "\n",
    "\n",
    "print(query(\"This is a query document about fruit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2768dbb6-47d6-4d04-93b1-bb4f586e3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! Iâ€™m doing great, thank you for asking! As an AI, I donâ€™t really *feel* in the way humans do, but my systems are running smoothly and Iâ€™m ready to help you with whatever you need. ðŸ˜Š\n",
      "\n",
      "How are *you* doing today? \n",
      "\n",
      "What can I do for you?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def chat(user_input):\n",
    "    messages = []\n",
    "    messages.append({'role': 'system', 'content': \"You are a helpful AI assistent that answer user's questions\"})\n",
    "    messages.append({'role': 'user', 'content': user_input})\n",
    "    \n",
    "    response = ollama.chat(model='gemma3', messages=messages)\n",
    "    reply = response['message']['content']\n",
    "    return reply\n",
    "\n",
    "user_message = 'Hello! how are you?'\n",
    "response = chat(user_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9339d118-7f09-4ca1-aff9-5fc587a66090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "collection = client.get_or_create_collection(\"chat-history\")\n",
    "\n",
    "text = f'User: {user_message}\\nAssistant: {response}'\n",
    "texts = [text]\n",
    "embeddings = embedder.encode(texts).tolist()\n",
    "ids = [str(uuid.uuid4()) for _ in texts]\n",
    "\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=texts,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded0b2eb-d8e2-4a97-a53c-548e8643dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['9ad8290a-e452-4740-af48-dd12ff68e268']], 'embeddings': None, 'documents': [['User: Hello! how are you?\\nAssistant: Hello there! Iâ€™m doing great, thank you for asking! As an AI, I donâ€™t really *feel* in the way humans do, but my systems are running smoothly and Iâ€™m ready to help you with whatever you need. ðŸ˜Š\\n\\nHow are *you* doing today? \\n\\nWhat can I do for you?']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[1.1170940399169922]]}\n"
     ]
    }
   ],
   "source": [
    "query_text = 'How are you?'\n",
    "\n",
    "query_vector = embedder.encode(query_text)\n",
    "\n",
    "# Query Chroma\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_vector],\n",
    "    n_results=5,\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e813fc-bcc4-43bd-a4a8-f487e78a430e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
