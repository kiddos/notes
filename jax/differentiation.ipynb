{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b716cb-f4d1-4f00-9285-b8f2049bc59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 21:37:53.083507: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.1 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "10.0\n",
      "6.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "def f(x):\n",
    "  return x**3 + 2*x**2 - 3*x + 1\n",
    "\n",
    "dfdx = jax.grad(f)\n",
    "d2fdx = jax.grad(dfdx)\n",
    "d3fdx = jax.grad(d2fdx)\n",
    "d4fdx = jax.grad(d3fdx)\n",
    "\n",
    "print(dfdx(1.))\n",
    "print(d2fdx(1.))\n",
    "print(d3fdx(1.))\n",
    "print(d4fdx(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f29ff8d-7ceb-497f-9089-ae857740ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def g(x):\n",
    "  return jnp.dot(x, x)\n",
    "\n",
    "h = jax.jacfwd(jax.grad(g))\n",
    "h(jnp.array([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e219109d-6967-42f2-bafa-a41412f3dea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2  1.2 -1.2]\n",
      "[ 1.2  2.4 -1.2]\n",
      "[ 1.2  2.4 -1.2]\n"
     ]
    }
   ],
   "source": [
    "def value_fn(theta, state):\n",
    "  return jnp.dot(theta, state)\n",
    "\n",
    "def td_loss_incorrect(theta, s_tm1, r_t, s_t):\n",
    "  v_tm1 = value_fn(theta, s_tm1)\n",
    "  target = r_t + value_fn(theta, s_t)\n",
    "  return -0.5 * ((target - v_tm1) ** 2)\n",
    "\n",
    "def td_loss_correct(theta, s_tm1, r_t, s_t):\n",
    "  v_tm1 = value_fn(theta, s_tm1)\n",
    "  target = r_t + value_fn(theta, s_t)\n",
    "  return -0.5 * ((jax.lax.stop_gradient(target) - v_tm1) ** 2)\n",
    "\n",
    "\n",
    "theta = jnp.array([0.1, -0.1, 0.])\n",
    "s_tm1 = jnp.array([1., 2., -1.])\n",
    "r_t = jnp.array(1.)\n",
    "s_t = jnp.array([2., 1., 0.])\n",
    "\n",
    "td_update_incorrect = jax.grad(td_loss_incorrect)\n",
    "delta_theta = td_update_incorrect(theta, s_tm1, r_t, s_t)\n",
    "print(delta_theta)\n",
    "\n",
    "td_update_correct = jax.grad(td_loss_correct)\n",
    "delta_theta = td_update_correct(theta, s_tm1, r_t, s_t)\n",
    "print(delta_theta)\n",
    "\n",
    "s_grad = jax.grad(value_fn)(theta, s_tm1)\n",
    "delta_theta_original_calculation = (r_t + value_fn(theta, s_t) - value_fn(theta, s_tm1)) * s_grad\n",
    "\n",
    "print(delta_theta_original_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99faa709-4d5c-43c6-a7e7-d02866e22814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x):  3.0\n",
      "straight_through_f(x): 3.0\n",
      "grad(f)(x): 0.0\n",
      "grad(straight_through_f)(x): 1.0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "  return jnp.round(x)  # non-differentiable\n",
    "\n",
    "def straight_through_f(x):\n",
    "  # Create an exactly-zero expression with Sterbenz lemma that has\n",
    "  # an exactly-one gradient.\n",
    "  zero = x - jax.lax.stop_gradient(x)\n",
    "  return zero + jax.lax.stop_gradient(f(x))\n",
    "\n",
    "print(\"f(x): \", f(3.2))\n",
    "print(\"straight_through_f(x):\", straight_through_f(3.2))\n",
    "\n",
    "print(\"grad(f)(x):\", jax.grad(f)(3.2))\n",
    "print(\"grad(straight_through_f)(x):\", jax.grad(straight_through_f)(3.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
