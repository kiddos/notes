{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcff63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d94c8f",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f2fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _eager_dataset_iterator at 0x7f033932ecf0>\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def prepare_image(x):\n",
    "    x = tf.cast(x['image'], tf.float32)\n",
    "    x = tf.reshape(x, (-1,))\n",
    "    return x\n",
    "\n",
    "ds_builder = tfds.builder('binarized_mnist')\n",
    "ds_builder.download_and_prepare()\n",
    "train_ds = ds_builder.as_dataset(split=tfds.Split.TRAIN)\n",
    "train_ds = train_ds.map(prepare_image)\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.shuffle(50000)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = iter(tfds.as_numpy(train_ds))\n",
    "\n",
    "test_ds = ds_builder.as_dataset(split=tfds.Split.TEST)\n",
    "test_ds = test_ds.map(prepare_image).batch(10000)\n",
    "test_ds = np.array(list(test_ds)[0])\n",
    "test_ds = jax.device_put(test_ds)\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539f264",
   "metadata": {},
   "source": [
    "### Create Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84df9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    latents: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        mean_x = nn.Dense(self.latents)(x)\n",
    "        logvar_x = nn.Dense(self.latents)(x)\n",
    "        return mean_x, logvar_x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, z):\n",
    "        z = nn.Dense(256)(z)\n",
    "        z = nn.relu(z)\n",
    "        z = nn.Dense(256)(z)\n",
    "        z = nn.relu(z)\n",
    "        z = nn.Dense(784)(z)\n",
    "        return z\n",
    "    \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    latents: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(self.latents)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def __call__(self, x, key):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        std = jnp.exp(0.5 * logvar)\n",
    "        eps = jax.random.normal(key, logvar.shape)\n",
    "        z = mean + std * eps\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mean, logvar\n",
    "    \n",
    "    def generate(self, z):\n",
    "        return nn.sigmoid(self.decoder(z))\n",
    "    \n",
    "\n",
    "\n",
    "def create_train_state(model, key):\n",
    "    @jax.jit\n",
    "    def init():\n",
    "        init_data = jnp.ones((BATCH_SIZE, 784), jnp.float32)\n",
    "        return model.init(key, init_data, key)['params']\n",
    "    \n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=init(),\n",
    "        tx=optax.adam(LEARNING_RATE))\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(666)\n",
    "model = VAE(latents=LATENT_SIZE)\n",
    "state = create_train_state(model, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16610c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n"
     ]
    }
   ],
   "source": [
    "example_batch = next(train_ds)\n",
    "print(example_batch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e2ca479",
   "metadata": {},
   "source": [
    "This is an very cool example of how vmap is used.\n",
    "\n",
    "for this example logits and labels both have shape `(128, 784)`.\n",
    "\n",
    "without `jax.vmap`, `binary_cross_entropy_with_logits` could compute the total sum of the matrix `(128, 784)`.\n",
    "\n",
    "With `jax.vmap`, `binary_cross_entropy_with_logits` would sum the `(, 784)` part and return shape of `(128)`\n",
    "\n",
    "and we can call `mean()` to get the mean of `(128)` losses.\n",
    "\n",
    "not sure why kl_divergence is computed like this\n",
    "\n",
    "it's supposed to be\n",
    "$\n",
    "\\sum p(x) log(\\frac{p(x)}{q(x)}) + (1-p(x)) log(\\frac{1-p(x)}{1-q(x)})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1058d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def binary_cross_entropy_with_logits(logits, labels):\n",
    "    logits = nn.log_sigmoid(logits)\n",
    "    return -jnp.sum(labels * logits + (1. - labels) * jnp.log(-jnp.expm1(logits)))\n",
    "\n",
    "@jax.vmap\n",
    "def kl_divergence(mean, logvar):\n",
    "    return -0.5 * jnp.sum(1 + logvar - jnp.square(mean) - jnp.exp(logvar))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch, z_key):\n",
    "    def loss_fn(params):\n",
    "        recon_x, mean, logvar = state.apply_fn({'params': params}, batch, z_key)\n",
    "        bce_loss = binary_cross_entropy_with_logits(recon_x, batch).mean()\n",
    "        kld_loss = kl_divergence(mean, logvar)\n",
    "        kld_loss = kld_loss.mean()\n",
    "        \n",
    "        loss = bce_loss + kld_loss\n",
    "        return loss\n",
    "    \n",
    "    grads = jax.grad(loss_fn)(state.params)\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "\n",
    "key, z_key, eval_key = jax.random.split(key, 3)\n",
    "test_state = train_step(state, example_batch, z_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdba2b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 µs ± 17.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_step(test_state, example_batch, z_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb8f3d3",
   "metadata": {},
   "source": [
    "`model.apply()` has a optional parameter `method`.\n",
    "\n",
    "we can use this `method` to tell jax which method to call instead of the `__call__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4873e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "(64, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(recon_x, x, mean, logvar):\n",
    "    bce_loss = binary_cross_entropy_with_logits(recon_x, x).mean()\n",
    "    kld_loss = kl_divergence(mean, logvar).mean()\n",
    "    return {\n",
    "        'bce': bce_loss,\n",
    "        'kld': kld_loss,\n",
    "        'loss': bce_loss + kld_loss\n",
    "    }\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval(state, batch, z, z_key):\n",
    "    model = VAE(latents=LATENT_SIZE)\n",
    "    recon_images, mean, logvar = state.apply_fn({'params': state.params}, batch, z_key)\n",
    "    comparison = jnp.concatenate([batch[:16].reshape(-1, 28, 28, 1),\n",
    "                                  recon_images[:16].reshape(-1, 28, 28, 1)])\n",
    "    generate_images = state.apply_fn({'params': state.params}, z, method=model.generate)\n",
    "    generate_images = generate_images.reshape(-1, 28, 28, 1)\n",
    "    metrics = compute_metrics(recon_images, batch, mean, logvar)\n",
    "    return metrics, comparison, generate_images\n",
    "\n",
    "\n",
    "z = jax.random.normal(z_key, (64, LATENT_SIZE))\n",
    "metrics, comparison, sample = eval(state, example_batch, z, eval_key)\n",
    "print(comparison.shape)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e1094",
   "metadata": {},
   "source": [
    "copy the following straight from the example.\n",
    "\n",
    "I am too lazy to implement this. :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1784b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(ndarray, fp, nrow=8, padding=2, pad_value=0.0, format=None):\n",
    "    if not (isinstance(ndarray, jnp.ndarray) or\n",
    "        (isinstance(ndarray, list) and all(isinstance(t, jnp.ndarray) for t in ndarray))):\n",
    "        raise TypeError('array_like of tensors expected, got {}'.format(type(ndarray)))\n",
    "\n",
    "    ndarray = jnp.asarray(ndarray)\n",
    "\n",
    "    if ndarray.ndim == 4 and ndarray.shape[-1] == 1:  # single-channel images\n",
    "        ndarray = jnp.concatenate((ndarray, ndarray, ndarray), -1)\n",
    "\n",
    "    # make the mini-batch of images into a grid\n",
    "    nmaps = ndarray.shape[0]\n",
    "    xmaps = min(nrow, nmaps)\n",
    "    ymaps = int(math.ceil(float(nmaps) / xmaps))\n",
    "    height, width = int(ndarray.shape[1] + padding), int(ndarray.shape[2] + padding)\n",
    "    num_channels = ndarray.shape[3]\n",
    "    grid = jnp.full((height * ymaps + padding, width * xmaps + padding, num_channels), pad_value).astype(jnp.float32)\n",
    "    k = 0\n",
    "    for y in range(ymaps):\n",
    "        for x in range(xmaps):\n",
    "            if k >= nmaps:\n",
    "                break\n",
    "            grid = grid.at[y * height + padding:(y + 1) * height,\n",
    "                           x * width + padding:(x + 1) * width].set(ndarray[k])\n",
    "            k = k + 1\n",
    "\n",
    "    # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "    ndarr = jnp.clip(grid * 255.0 + 0.5, 0, 255).astype(jnp.uint8)\n",
    "    im = Image.fromarray(ndarr.copy())\n",
    "    im.save(fp, format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39cf1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9609c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval epoch: 1, loss: 140.5900, BCE: 122.9232, KLD: 17.6668\n",
      "eval epoch: 2, loss: 122.3568, BCE: 101.5168, KLD: 20.8400\n",
      "eval epoch: 3, loss: 114.6378, BCE: 92.2613, KLD: 22.3764\n",
      "eval epoch: 4, loss: 110.6642, BCE: 88.0380, KLD: 22.6262\n",
      "eval epoch: 5, loss: 107.6390, BCE: 84.2557, KLD: 23.3833\n",
      "eval epoch: 6, loss: 106.5050, BCE: 82.6635, KLD: 23.8414\n",
      "eval epoch: 7, loss: 105.0298, BCE: 80.9643, KLD: 24.0655\n",
      "eval epoch: 8, loss: 104.3721, BCE: 79.8203, KLD: 24.5518\n",
      "eval epoch: 9, loss: 103.8689, BCE: 79.1262, KLD: 24.7428\n",
      "eval epoch: 10, loss: 102.9717, BCE: 78.2321, KLD: 24.7397\n",
      "eval epoch: 11, loss: 102.5942, BCE: 78.4284, KLD: 24.1658\n",
      "eval epoch: 12, loss: 102.7179, BCE: 77.3482, KLD: 25.3698\n",
      "eval epoch: 13, loss: 101.7541, BCE: 77.2554, KLD: 24.4987\n",
      "eval epoch: 14, loss: 101.6877, BCE: 76.4036, KLD: 25.2841\n",
      "eval epoch: 15, loss: 101.3727, BCE: 76.4956, KLD: 24.8771\n",
      "eval epoch: 16, loss: 100.9258, BCE: 75.7253, KLD: 25.2005\n",
      "eval epoch: 17, loss: 100.7445, BCE: 75.4332, KLD: 25.3113\n",
      "eval epoch: 18, loss: 100.4762, BCE: 74.9608, KLD: 25.5154\n",
      "eval epoch: 19, loss: 100.3540, BCE: 75.1636, KLD: 25.1904\n",
      "eval epoch: 20, loss: 100.3980, BCE: 74.8971, KLD: 25.5009\n",
      "eval epoch: 21, loss: 100.2955, BCE: 75.2518, KLD: 25.0437\n",
      "eval epoch: 22, loss: 100.1360, BCE: 74.6464, KLD: 25.4896\n",
      "eval epoch: 23, loss: 99.7745, BCE: 74.6399, KLD: 25.1346\n",
      "eval epoch: 24, loss: 99.8258, BCE: 74.9121, KLD: 24.9138\n",
      "eval epoch: 25, loss: 99.5506, BCE: 74.0190, KLD: 25.5316\n",
      "eval epoch: 26, loss: 99.6921, BCE: 74.2899, KLD: 25.4022\n",
      "eval epoch: 27, loss: 99.2133, BCE: 74.0032, KLD: 25.2101\n",
      "eval epoch: 28, loss: 99.5094, BCE: 73.7492, KLD: 25.7601\n",
      "eval epoch: 29, loss: 99.2109, BCE: 73.7158, KLD: 25.4951\n",
      "eval epoch: 30, loss: 99.1798, BCE: 73.5287, KLD: 25.6511\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "STEPS_PER_EPOCH = 50000 // BATCH_SIZE\n",
    "\n",
    "def train_and_evaluate():\n",
    "    key = jax.random.PRNGKey(666)\n",
    "    key, z_key = jax.random.split(key)\n",
    "    z = jax.random.normal(z_key, (64, LATENT_SIZE))\n",
    "    model = VAE(latents=LATENT_SIZE)\n",
    "    state = create_train_state(model, key)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for _ in range(STEPS_PER_EPOCH):\n",
    "            batch = next(train_ds)\n",
    "            key, z_key = jax.random.split(key)\n",
    "            state = train_step(state, batch, z_key)\n",
    "        \n",
    "        metrics, comparison, sample = eval(state, test_ds, z, eval_key)\n",
    "        save_image(comparison, f'results/reconstruction_{epoch}.png', nrow=8)\n",
    "        save_image(sample, f'results/sample_{epoch}.png', nrow=8)\n",
    "        print('eval epoch: {}, loss: {:.4f}, BCE: {:.4f}, KLD: {:.4f}'.format(\n",
    "            epoch + 1, metrics['loss'], metrics['bce'], metrics['kld']\n",
    "        ))\n",
    "\n",
    "\n",
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
